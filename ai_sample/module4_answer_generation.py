#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¨¡å—4ï¼šå›žç­”ç”Ÿæˆæ¨¡å—
åŠŸèƒ½ï¼šä½¿ç”¨æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡å’Œç”¨æˆ·é—®é¢˜ï¼Œé€šè¿‡è¯­è¨€æ¨¡åž‹ç”Ÿæˆè‡ªç„¶è¯­è¨€å›žç­”
è¾“å…¥ï¼šç”¨æˆ·é—®é¢˜ + æ£€ç´¢ä¸Šä¸‹æ–‡
è¾“å‡ºï¼šç”Ÿæˆçš„å›žç­”æ–‡æœ¬ï¼ˆå¯åŒ…å«å‚è€ƒé“¾æŽ¥ï¼‰
"""

import json
import os
from typing import List, Dict, Any, Optional
import openai
from module3_semantic_search import SemanticSearcher

class AnswerGenerator:
    """
    å›žç­”ç”Ÿæˆå™¨ç±»
    """
    
    def __init__(self, use_openai: bool = False, api_key: Optional[str] = None):
        """
        åˆå§‹åŒ–å›žç­”ç”Ÿæˆå™¨
        Args:
            use_openai: æ˜¯å¦ä½¿ç”¨OpenAI API
            api_key: OpenAI APIå¯†é’¥
        """
        self.use_openai = use_openai
        self.searcher = None
        
        if use_openai:
            if api_key:
                openai.api_key = api_key
            else:
                # å°è¯•ä»ŽçŽ¯å¢ƒå˜é‡èŽ·å–APIå¯†é’¥
                openai.api_key = os.getenv("OPENAI_API_KEY")
            
            if not openai.api_key:
                print("è­¦å‘Šï¼šæœªæ‰¾åˆ°OpenAI APIå¯†é’¥ï¼Œå°†ä½¿ç”¨æ¨¡æ¿å›žç­”æ¨¡å¼")
                self.use_openai = False
    
    def initialize_searcher(self, tensor_file: str, id_map_file: str, faiss_index_file: str = None):
        """
        åˆå§‹åŒ–è¯­ä¹‰æ£€ç´¢å™¨
        """
        self.searcher = SemanticSearcher()
        self.searcher.initialize(tensor_file, id_map_file, faiss_index_file)
    
    def create_prompt(self, question: str, context_results: List[Dict[str, Any]]) -> str:
        """
        åˆ›å»ºç»™è¯­è¨€æ¨¡åž‹çš„æç¤ºè¯
        """
        # æž„å»ºä¸Šä¸‹æ–‡ä¿¡æ¯
        context_text = ""
        for i, result in enumerate(context_results, 1):
            context_text += f"\nå‚è€ƒèµ„æ–™ {i}:\n"
            context_text += f"é—®é¢˜: {result['question']}\n"
            context_text += f"ç­”æ¡ˆ: {result['answer']}\n"
            if result['link']:
                context_text += f"é“¾æŽ¥: {result['link']}\n"
            if result['tags']:
                context_text += f"æ ‡ç­¾: {', '.join(result['tags'])}\n"
            context_text += "\n"
        
        # åˆ›å»ºæç¤ºè¯
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¢¨å°”æœ¬ç”Ÿæ´»åŠ©æ‰‹ï¼Œä¸“é—¨å›žç­”å…³äºŽå¢¨å°”æœ¬äº¤é€šã€ç”Ÿæ´»ç­‰æ–¹é¢çš„é—®é¢˜ã€‚

ç”¨æˆ·é—®é¢˜: {question}

å‚è€ƒèµ„æ–™:{context_text}

è¯·æ ¹æ®ä¸Šè¿°å‚è€ƒèµ„æ–™ï¼Œä¸ºç”¨æˆ·æä¾›å‡†ç¡®ã€æœ‰ç”¨çš„ä¸­æ–‡å›žç­”ã€‚è¦æ±‚ï¼š
1. å›žç­”è¦ç®€æ´æ˜Žäº†ï¼Œç›´æŽ¥è§£å†³ç”¨æˆ·é—®é¢˜
2. å¦‚æžœå‚è€ƒèµ„æ–™ä¸­æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·ç»“åˆè¿™äº›ä¿¡æ¯ç»™å‡ºç­”æ¡ˆ
3. å¦‚æžœæœ‰æœ‰ç”¨çš„é“¾æŽ¥ï¼Œè¯·åœ¨å›žç­”æœ«å°¾æä¾›
4. ç”¨å‹å¥½ã€ä¸“ä¸šçš„è¯­æ°”å›žç­”
5. å¦‚æžœå‚è€ƒèµ„æ–™ä¸è¶³ä»¥å›žç­”é—®é¢˜ï¼Œè¯·è¯šå®žè¯´æ˜Žå¹¶ç»™å‡ºå»ºè®®

å›žç­”:"""
        
        return prompt
    
    def generate_with_openai(self, prompt: str) -> str:
        """
        ä½¿ç”¨OpenAI APIç”Ÿæˆå›žç­”
        """
        try:
            response = openai.ChatCompletion.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¢¨å°”æœ¬ç”Ÿæ´»åŠ©æ‰‹ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=500,
                temperature=0.7
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            print(f"OpenAI APIè°ƒç”¨å¤±è´¥: {e}")
            return None
    
    def generate_template_answer(self, question: str, context_results: List[Dict[str, Any]]) -> str:
        """
        ç”Ÿæˆæ¨¡æ¿å¼å›žç­”ï¼ˆä¸ä½¿ç”¨OpenAIæ—¶çš„å¤‡é€‰æ–¹æ¡ˆï¼‰
        """
        if not context_results:
            return f"æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰æ‰¾åˆ°å…³äºŽ'{question}'çš„ç›¸å…³ä¿¡æ¯ã€‚å»ºè®®æ‚¨æŸ¥çœ‹å¢¨å°”æœ¬å®˜æ–¹ç½‘ç«™æˆ–å’¨è¯¢ç›¸å…³éƒ¨é—¨ã€‚"
        
        # ä½¿ç”¨æœ€ç›¸å…³çš„ç»“æžœç”Ÿæˆå›žç­”
        best_result = context_results[0]
        
        answer = f"æ ¹æ®æˆ‘çš„çŸ¥è¯†åº“ï¼Œå…³äºŽæ‚¨çš„é—®é¢˜'{question}'ï¼š\n\n"
        answer += f"{best_result['answer']}\n\n"
        
        # æ·»åŠ æ›´å¤šä¸Šä¸‹æ–‡
        if len(context_results) > 1:
            answer += "ç›¸å…³ä¿¡æ¯ï¼š\n"
            for i, result in enumerate(context_results[1:3], 1):  # æœ€å¤šæ˜¾ç¤º2ä¸ªé¢å¤–ç»“æžœ
                answer += f"{i}. {result['question']} - {result['answer']}\n"
            answer += "\n"
        
        # æ·»åŠ é“¾æŽ¥
        links = [r['link'] for r in context_results[:3] if r['link']]
        if links:
            answer += "è¯¦ç»†ä¿¡æ¯è¯·å‚è€ƒï¼š\n"
            for i, link in enumerate(links, 1):
                answer += f"{i}. {link}\n"
        
        return answer
    
    def generate_answer(self, question: str, k: int = 3) -> Dict[str, Any]:
        """
        ä¸»è¦çš„å›žç­”ç”Ÿæˆå‡½æ•°
        """
        if self.searcher is None:
            raise ValueError("è¯·å…ˆåˆå§‹åŒ–è¯­ä¹‰æ£€ç´¢å™¨")
        
        print(f"æ­£åœ¨ä¸ºé—®é¢˜ç”Ÿæˆå›žç­”: '{question}'")
        
        # 1. æ£€ç´¢ç›¸å…³ä¸Šä¸‹æ–‡
        context_results = self.searcher.search(question, k=k)
        
        # 2. ç”Ÿæˆå›žç­”
        if self.use_openai:
            prompt = self.create_prompt(question, context_results)
            generated_answer = self.generate_with_openai(prompt)
            
            if generated_answer is None:
                print("OpenAIç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ¿å›žç­”")
                generated_answer = self.generate_template_answer(question, context_results)
        else:
            generated_answer = self.generate_template_answer(question, context_results)
        
        # 3. æž„å»ºæœ€ç»ˆç»“æžœ
        result = {
            "question": question,
            "answer": generated_answer,
            "search_results": context_results,
            "sources": [r['link'] for r in context_results if r['link']],
            "confidence": context_results[0]['score'] if context_results else 0.0
        }
        
        return result
    
    def batch_generate_answers(self, questions: List[str], k: int = 3) -> List[Dict[str, Any]]:
        """
        æ‰¹é‡ç”Ÿæˆå›žç­”
        """
        results = []
        for question in questions:
            try:
                result = self.generate_answer(question, k)
                results.append(result)
            except Exception as e:
                print(f"ç”Ÿæˆå›žç­”å¤±è´¥ '{question}': {e}")
                results.append({
                    "question": question,
                    "answer": "æŠ±æ­‰ï¼Œç”Ÿæˆå›žç­”æ—¶å‡ºçŽ°é”™è¯¯ã€‚",
                    "search_results": [],
                    "sources": [],
                    "confidence": 0.0
                })
        return results

def test_answer_generation():
    """
    æµ‹è¯•å›žç­”ç”Ÿæˆç³»ç»Ÿ
    """
    print("=== æ¨¡å—4ï¼šå›žç­”ç”Ÿæˆæ¨¡å—æµ‹è¯• ===")
    
    # æ–‡ä»¶è·¯å¾„
    tensor_file = "qa_tensors.pt"
    id_map_file = "id_map.json"
    faiss_index_file = "qa_faiss_index.index"
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    required_files = [tensor_file, id_map_file]
    for file_path in required_files:
        if not os.path.exists(file_path):
            print(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ {file_path}")
            print("è¯·å…ˆè¿è¡Œæ¨¡å—2å’Œæ¨¡å—3ç”Ÿæˆå¿…è¦æ–‡ä»¶")
            return
    
    # åˆå§‹åŒ–å›žç­”ç”Ÿæˆå™¨ï¼ˆä½¿ç”¨æ¨¡æ¿æ¨¡å¼ï¼Œä¸éœ€è¦OpenAI APIï¼‰
    generator = AnswerGenerator(use_openai=False)
    generator.initialize_searcher(tensor_file, id_map_file, faiss_index_file)
    
    # æµ‹è¯•é—®é¢˜åˆ—è¡¨
    test_questions = [
        "å¢¨å°”æœ¬æ€Žä¹ˆåå…¬äº¤è½¦ï¼Ÿ",
        "å¦‚ä½•ä½¿ç”¨Mykiå¡ï¼Ÿ",
        "å­¦ç”Ÿä¹˜è½¦æœ‰ä¼˜æƒ å—ï¼Ÿ",
        "ä»Žæœºåœºåˆ°å¸‚åŒºæ€Žä¹ˆèµ°ï¼Ÿ",
        "å¢¨å°”æœ¬åœè½¦éœ€è¦æ³¨æ„ä»€ä¹ˆï¼Ÿ"
    ]
    
    print("\n=== å¼€å§‹æµ‹è¯•å›žç­”ç”Ÿæˆ ===")
    
    for i, question in enumerate(test_questions, 1):
        print(f"\n{'='*60}")
        print(f"æµ‹è¯• {i}: {question}")
        print('='*60)
        
        try:
            result = generator.generate_answer(question)
            
            print(f"ç”Ÿæˆçš„å›žç­”:")
            print(result['answer'])
            print(f"\nç½®ä¿¡åº¦: {result['confidence']:.4f}")
            
            if result['sources']:
                print(f"\nå‚è€ƒé“¾æŽ¥:")
                for j, source in enumerate(result['sources'][:3], 1):
                    print(f"{j}. {source}")
                    
        except Exception as e:
            print(f"å›žç­”ç”Ÿæˆå¤±è´¥: {e}")

def interactive_qa():
    """
    äº¤äº’å¼é—®ç­”æµ‹è¯•
    """
    print("=== äº¤äº’å¼é—®ç­”ç³»ç»Ÿæµ‹è¯• ===")
    
    # æ–‡ä»¶è·¯å¾„
    tensor_file = "qa_tensors.pt"
    id_map_file = "id_map.json"
    faiss_index_file = "qa_faiss_index.index"
    
    # åˆå§‹åŒ–å›žç­”ç”Ÿæˆå™¨
    generator = AnswerGenerator(use_openai=False)
    generator.initialize_searcher(tensor_file, id_map_file, faiss_index_file)
    
    print("\næ¬¢è¿Žä½¿ç”¨å¢¨å°”æœ¬ç”Ÿæ´»åŠ©æ‰‹ï¼")
    print("è¾“å…¥é—®é¢˜èŽ·å–ç­”æ¡ˆï¼ˆè¾“å…¥'quit'é€€å‡ºï¼‰:")
    
    while True:
        question = input("\nè¯·è¾“å…¥é—®é¢˜: ").strip()
        
        if question.lower() == 'quit':
            break
        
        if not question:
            continue
        
        try:
            result = generator.generate_answer(question)
            
            print(f"\nðŸ¤– åŠ©æ‰‹å›žç­”:")
            print(result['answer'])
            
            if result['sources']:
                print(f"\nðŸ“š å‚è€ƒé“¾æŽ¥:")
                for i, source in enumerate(result['sources'][:2], 1):
                    print(f"{i}. {source}")
                    
        except Exception as e:
            print(f"âŒ å›žç­”ç”Ÿæˆå‡ºé”™: {e}")
    
    print("\næ„Ÿè°¢ä½¿ç”¨å¢¨å°”æœ¬ç”Ÿæ´»åŠ©æ‰‹ï¼")

def main():
    """
    ä¸»å‡½æ•°
    """
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == "--interactive":
        interactive_qa()
    else:
        test_answer_generation()

if __name__ == "__main__":
    main() 